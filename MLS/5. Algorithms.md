# Algorithms

Algorithms SageMaker offers out of the box.

### Regression

**Linear Learner**:

- Minimize errors through SGD
- Can also be used for classification (long, short)

**Factorization Machines Algorithms** - can handles situations when some data are missing

- Supervised
- Classification & Regression
- Captures interaction between features with high dimensional **sparse** dataset

Limitations:

- Only consider pair-wise relations at a time (SageMaker's implementation)

- CSV not supported
- Doesn't work for multiclaassd
- Needs lots of data
- CPU rock sparse data better
- Don't perform well on dense data

Use case:

Has very sparse dataset

Recommendation system

Futher reading: [Factorization Machines for Item Recommendation with Implicit Feedback Data](https://towardsdatascience.com/factorization-machines-for-item-recommendation-with-implicit-feedback-data-5655a7c749db)

### Clustering

**SageMaker's Implementation of  K-Means**

- Expects tabular data
- Define the identifying attributes - attributes that defines similarity
- Variant: web-scale K-means

### Classification

**Image Analysis**

- Image Classification
- Object Detection
- Semantic Segmentation

Use case:

- Image Metadata Extraction
- Computer Vision System

### Anomaly Detection

**Random Cut Forest**

- Detect anomalous data points within a set, like spikes in time series data. RCF works with n-dimentional data, even when it's hard to plot.
  - Gives an antmaly score to data points.
  - Scales well.
  - Does not benefit from GPU

- It makes a random cut, the outliers tends to stay on one side, while the majority stays on another side.
- Use case
  - Quality Control
  - Fraud Detection 

**IP Insights**

- Learn usage of IPv4 addresses by capturing associations between IP addresses and various entities such as user IDs.

- Can flag odd online behaviours for future review.

- Process:
  - Ingest Entities-IP pairs: build a historical baseline pattern
  - Return inference via a score

- Use case
  - Tiered authentication
  - fraud detection

### Text Analysis

**Latent Dirichlet Allocation (LDA)** - documents similarity

Concept

- Unsupervised
- To describe a set of observations(documents) as a mixture of distinct categories
- To discover a user-specified number of topics shared by documents

Use to figure out how similar documents are based on the frequency of similar words (based on the presence of words in each document)

- Article recommendation
- Musical Influence Modeling

**Neural Topic Model (NTM)**

- Unsupervised
- Organize a corpus of documents into topics that contain word groupings based on their statistical distribution.

**Seq2seq**

**Blazing Text** (based on FastText)

Highly optimized implementation of Word2Vec

Can be used in

- Word2vec manner
- text classification manner

**Object2Vec**

General purpose neural embedding algorithm that can learn low dim dense embeddings of high-dim objects while preserving the semantics of relationships between the pairs in the original embedding space.

Use case:

- movie rating prediction
- genral classification

### Reinforcement Learning

Motivate toward desired goal. Learn a policy that optimizes for an agent acting in an environment.

### Forcast Learning

#### DeepAR

**Concept**

Forecasting algorithm for scalar time series using RNN. DeepAR outperforms standard autoregressive and exponential smoothing.

DeepAR seeks to be better than traditional time-series algorithms by accommodating multiple cross-sectional datasets.

**Cold start problem**: 

- Little or no history to use for building a forecasting model
- Solution: can combine multiple model (by letting DeepAR to look at multiple datasets)

**Forcast type**

- Point in time: sneakers sold at week 7 is X
- Probablistic forecast: Number of sneakers sold in week 7 is between X and Y with a Z% probability.

### Ensemble Learning

Use multiple algorithms and models collectively to hopefully improve model accuracy

#### Extreme gradient boosting (XGBoost)

Open-source implementation of the gradient boosted trees. It predict target variables by combining the estimates of a set of simpler and weaker models.

- 2 required and 35 optional hyperparameters
- Extremely flexible, can be used in  regression, binary classification, and multi-class classification.

### Recommendation System

**Content-based Filtering**

[Google - Content-based Filtering](https://developers.google.com/machine-learning/recommendation/content-based/basics)

Content-based filtering uses item features to recommend other items similar to what the user likes, based on their previous actions or explicit feedback.

**Collaborative filtering**:

[Google - Collaborative Filtering](https://developers.google.com/machine-learning/recommendation/collaborative/basics)

协同过滤是一种在推荐系统中广泛使用的技术。该技术通过分析用户或者事物之间的相似性，来预测用户可能感兴趣的内容并将此内容推荐给用户。这里的相似性可以是人口特征的相似性，也可以是历史浏览内容的相似性，还可以是个人通过一定机制给予某个事物的回应。